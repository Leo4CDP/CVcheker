{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Resume base compliance with job description**"
      ],
      "metadata": {
        "id": "hOY5YIonDhhC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code was created for automatic verification of resumes (in txt format) - identifying whether the generated resume database matches the published job posting.\n",
        "\n",
        "**To start the script:**\n",
        "\n",
        "**1. add job description in txt format as \"job_description.txt\";**\n",
        "\n",
        "**2. create a folder CV_base, into which add resume files (in txt format).**\n",
        "\n",
        "Used method:  TFxIDF  (term frequency - inverse document frequency)"
      ],
      "metadata": {
        "id": "POAkfbMUC4Pb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Creating the environment**"
      ],
      "metadata": {
        "id": "ynxPw00BXnqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import os\n",
        "import chardet"
      ],
      "metadata": {
        "id": "lFuyYce_fIm8"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Introduce reading files function**\n",
        "We use sorting of filenames in alphabetical order"
      ],
      "metadata": {
        "id": "jkgGKA5MYn3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_documents(directory,code_scheme):\n",
        "    documents = []\n",
        "    filenames = os.listdir(directory)\n",
        "    filenames.sort()\n",
        "    for filename in filenames:\n",
        "            with open(os.path.join(directory, filename), 'r', encoding=code_scheme) as f:\n",
        "               documents.append(f.read())\n",
        "    return documents"
      ],
      "metadata": {
        "id": "dGskr4O4k6Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to get filenames (used on stage of outputs)"
      ],
      "metadata": {
        "id": "8eWPOFH008zy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filenames_list(directory):\n",
        "    documents = []\n",
        "    filenames = os.listdir(directory)\n",
        "    filenames.sort()\n",
        "    return filenames"
      ],
      "metadata": {
        "id": "gf_RMcYtoDnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer()"
      ],
      "metadata": {
        "id": "XR8lOnFOAIsA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Choose coding for the txt files (UTF-8 for English, ISO-8859-2 for Hungarian language)"
      ],
      "metadata": {
        "id": "1eiFH_VmHngb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For Hungarian & English language\n",
        "#encoding='ISO-8859-2'\n",
        "\n",
        "#For English language\n",
        "encoding='UTF-8'"
      ],
      "metadata": {
        "id": "x2Ru5xi_Hzuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may change sensitivity - the number of resumes to show after check. 0.3 = top 30% from the base."
      ],
      "metadata": {
        "id": "IUBYi6-kMAw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sensitivity = 0.3"
      ],
      "metadata": {
        "id": "KEYMHu9BL_m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Create base of txt files for futher processing**\n"
      ],
      "metadata": {
        "id": "GN_oDyJkcXqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vacancy = job_description.txt\n",
        "folder = 'CV_base/'\n",
        "\n",
        "txt_documents = read_documents(folder,encoding)"
      ],
      "metadata": {
        "id": "68mrG1ywcWP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the same vectoriser from task 1: TfidfVectorizer\n",
        "\n",
        "We create a tf-idf table to show the weights of each word in each CV document!"
      ],
      "metadata": {
        "id": "KzfTlOfCcNJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_t2 = TfidfVectorizer()\n",
        "tfidf_matrix_t2 = vectorizer_t2.fit_transform(txt_documents)\n",
        "tfidf_df_t2 = pd.DataFrame(tfidf_matrix_t2.toarray(), columns=vectorizer_t2.get_feature_names_out())\n",
        "print(tfidf_df_t2)"
      ],
      "metadata": {
        "id": "RTkNjai7k-_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate number of elements in the txt_documents list"
      ],
      "metadata": {
        "id": "tiBwc32liqWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_elements = len(txt_documents)\n",
        "last_document_index = num_elements - 1"
      ],
      "metadata": {
        "id": "ANcBLc9qikzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate similarity for each element in the txt_documents list.\n"
      ],
      "metadata": {
        "id": "3prVao0UimLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarities_t2 = cosine_similarity(vacancy, tfidf_matrix_t2)\n",
        "print('similarities_t2:',similarities_t2)\n",
        "similarities_t2.shape"
      ],
      "metadata": {
        "id": "i2ETamVxikM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the top 30% of CVs based on similarity to vacancy description"
      ],
      "metadata": {
        "id": "bLi9si3p7FTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_top_elements = int(sensitivity * len(similarities_t2.flatten()))\n",
        "top_indices = np.argsort(similarities_t2.flatten())[-num_top_elements:]\n",
        "\n",
        "filenames = filenames_list(folder)\n",
        "top_filenames = [filenames[i] for i in top_indices]\n",
        "top_similarities = similarities_t2.flatten()[top_indices]\n",
        "\n",
        "for filename, similarity in zip(top_filenames, top_similarities):\n",
        "    print(f\"Filename: {filename}\")\n",
        "    print(f\"Similarity: {similarity}\")\n"
      ],
      "metadata": {
        "id": "qGVMP8IPl94Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}